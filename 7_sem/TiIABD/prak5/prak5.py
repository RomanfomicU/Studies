# -*- coding: utf-8 -*-
"""prak5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1um9IUBcjWaMqovspcNNKFy2V5VnLMdTp
"""

import pandas as pd
import matplotlib.pyplot as plt
from sklearn.metrics import classification_report
import numpy as np
import plotly.express as px
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import confusion_matrix

"""# Задание 1"""

df=pd.read_csv('sample_data/data.csv')
df.head()

"""# Задание 2"""

balance = df['diagnosis'].value_counts()

print(balance)

plt.bar(balance.index, balance.values)
plt.xlabel('Диагноз')
plt.ylabel('Количество записей')
plt.title('Баланс классов')
plt.xticks(balance.index, ['B', 'M'])
plt.show()

"""# Задание 3"""

target = df.iloc[:, 1]
predictors = df.iloc[:, 2:-1]

x_train, x_test, y_train, y_test = train_test_split(predictors, target, train_size=0.2, shuffle=True, random_state=42)

print('Размер для признаков обучающей выборки', x_train.shape)
print('Размер для признаков тестовой выборки', x_test.shape)
print('Размер для целевого показателя обучающей выборки', y_train.shape)
print('Размер для показателя тестовой выборки', y_test.shape)

"""# Задание 4"""

print('Исходные значения: ', np.array(y_test))

#Logistic regression
print("Logistic Regression:")
model = LogisticRegression()
model.fit(x_train, y_train)
y_predict = model.predict(x_test)
print('Предсказанные значения: ', y_predict)

# Матрица ошибок
plt.rcParams['figure.figsize'] = (10, 10)
fig = px.imshow(confusion_matrix(y_test, y_predict), text_auto=True)
fig.update_layout(xaxis_title="Target", yaxis_title="Prediction")
fig.show()

#SVC
print("SVM:")
param_kernel = ('linear', 'rbf', 'poly', 'sigmoid') # для перебора ядер
parameters = {'kernel': param_kernel}
model = SVC()
grid_search_svm = GridSearchCV(estimator = model, param_grid = parameters, cv = 6) # сетка для перебора параметров
grid_search_svm.fit(x_train, y_train) # обучаем модели с разными параметрами
best_model = grid_search_svm.best_estimator_
print(best_model.kernel)
svm_preds = best_model.predict(x_test)
print('Предсказанные значения: ', svm_preds)

# Матрица ошибок SVM
plt.rcParams['figure.figsize'] = (10, 10)
fig = px.imshow(confusion_matrix(y_test, svm_preds), text_auto=True)
fig.update_layout(xaxis_title="Target", yaxis_title="SVM Prediction")
fig.show()

# KNN
print("KNN:")
number_of_neighbors = np.arange(3, 10) # количество соседей для перебора
model_KNN = KNeighborsClassifier() # нициализация модели
params = {"n_neighbors": number_of_neighbors}
grid_search = GridSearchCV(estimator=model_KNN, param_grid=params, cv=6)    # задание параметров для поиска по сетке
grid_search.fit(x_train, y_train) # обучение модели
print(grid_search.best_score_) # лучшее значение macro-average
print(grid_search.best_estimator_) # лучшая модель получается при k = 3
knn_preds = grid_search.predict(x_test) # результат работы модели для тестовых данных
print('Предсказанные значения: ',knn_preds)

# Матрица ошибок KNN
plt.rcParams['figure.figsize'] = (10, 10)
fig = px.imshow(confusion_matrix(y_test, knn_preds), text_auto=True)
fig.update_layout(xaxis_title="Target", yaxis_title="KNN Prediction")
fig.show()

"""# Задание 5"""

print(classification_report(y_predict, y_test))
print(classification_report(svm_preds, y_test))
print(classification_report(knn_preds, y_test))